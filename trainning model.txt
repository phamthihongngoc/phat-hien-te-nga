# C√ÄI ƒê·∫∂T C√ÅC TH∆Ø VI·ªÜN C·∫¶N THI·∫æT (N·∫æU CH∆ØA C√ì)
!pip install imbalanced-learn torchinfo

!pip install matplotlib-venn

!apt-get -qq install -y libfluidsynth1

# https://pypi.python.org/pypi/libarchive
!apt-get -qq install -y libarchive-dev && pip install -U libarchive

# https://pypi.python.org/pypi/pydot
!apt-get -qq install -y graphviz && pip install pydot
import pydot

!pip install cartopy

import cartopy
import libarchive
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report, precision_score, recall_score, f1_score
import seaborn as sns
import matplotlib.pyplot as plt
import time
from sklearn.manifold import TSNE
from torchinfo import summary
import pandas as pd
import os

# B∆Ø·ªöC 1: UPLOAD FILE D·ªÆ LI·ªÜU TR√äN GOOGLE COLAB
from google.colab import files

uploaded = files.upload()  # M·ªü h·ªôp tho·∫°i ƒë·ªÉ t·∫£i file l√™n
print("Danh s√°ch file ƒë√£ t·∫£i l√™n:", os.listdir())

# B∆Ø·ªöC 2: LOAD D·ªÆ LI·ªÜU
X = np.load("X_balanced1.npy")
y = np.load("y_balanced1.npy")

print(f"S·ªë l∆∞·ª£ng c·ª≠a s·ªï tr∆∞·ª£t: {len(X)}")
print(f"Shape c·ªßa X: {X.shape} (s·ªë c·ª≠a s·ªï, 50 m·∫´u, 6 ƒë·∫∑c tr∆∞ng)")
print(f"Shape c·ªßa y: {y.shape} (s·ªë c·ª≠a s·ªï)")

# Chia t·∫≠p train/test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
print("S·ªë m·∫´u trong t·∫≠p hu·∫•n luy·ªán:", X_train.shape[0])
print("S·ªë m·∫´u trong t·∫≠p ki·ªÉm tra:", X_test.shape[0])

# B∆Ø·ªöC 3: X√ÇY D·ª∞NG M√î H√åNH CNN + LSTM
def build_model(input_shape):
    model = models.Sequential([
        layers.Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=input_shape),
        layers.MaxPooling1D(pool_size=2),
        layers.Conv1D(filters=128, kernel_size=3, activation='relu'),
        layers.MaxPooling1D(pool_size=2),
        layers.LSTM(64, return_sequences=True),
        layers.LSTM(64),
        layers.Dense(128, activation='relu'),
        layers.Dropout(0.3),
        layers.Dense(5, activation='softmax')  # 5 l·ªõp (t∆∞∆°ng ·ª©ng 5 h√†nh ƒë·ªông)
    ])
    
    model.compile(optimizer='adam', 
                  loss='sparse_categorical_crossentropy', 
                  metrics=['accuracy'])
    return model

model = build_model((50, 6))
model.summary()

# B∆Ø·ªöC 4: HU·∫§N LUY·ªÜN M√î H√åNH
start_time = time.time()
history = model.fit(X_train, y_train, epochs=50, batch_size=1, validation_split=0.2)
end_time = time.time()
inference_time = (end_time - start_time) / len(X_test)
print(f"Inference Time: {inference_time:.6f} s/m·∫´u")

# L∆ØU M√î H√åNH SAU KHI HU·∫§N LUY·ªÜN
model.save("/content/fall_detection_model.h5")
print("‚úÖ ƒê√£ l∆∞u m√¥ h√¨nh v√†o fall_detection_model.h5")

# T√≠nh trung b√¨nh Validation Loss v√† Validation Accuracy
mean_val_loss = np.mean(history.history['val_loss'])
mean_val_accuracy = np.mean(history.history['val_accuracy'])

print(f"\nValidation Loss: {mean_val_loss:.4f}")
print(f"Validation Accuracy: {mean_val_accuracy:.4f}")

# B∆Ø·ªöC 5: ƒê√ÅNH GI√Å M√î H√åNH
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score, f1_score

# D·ª± ƒëo√°n
y_pred = model.predict(X_test).argmax(axis=1)

# T·∫°o b√°o c√°o ph√¢n lo·∫°i d∆∞·ªõi d·∫°ng b·∫£ng
report = classification_report(y_test, y_pred, output_dict=True)
report_df = pd.DataFrame(report).transpose()

# Hi·ªÉn th·ªã b√°o c√°o d∆∞·ªõi d·∫°ng b·∫£ng
print("üìä B√°o c√°o ph√¢n lo·∫°i:")
print(report_df)

# T√≠nh to√°n Precision, Recall, F1-score th·ªß c√¥ng v√† hi·ªÉn th·ªã d∆∞·ªõi d·∫°ng b·∫£ng
metrics_data = {
    "Metric": ["Precision", "Recall", "F1-score"],
    "Value": [
        precision_score(y_test, y_pred, average='macro'),
        recall_score(y_test, y_pred, average='macro'),
        f1_score(y_test, y_pred, average='macro')
    ]
}
metrics_df = pd.DataFrame(metrics_data)
print("\nüìå Ch·ªâ s·ªë t·ªïng qu√°t:")
print(metrics_df)

# V·∫Ω Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))
plt.title("Confusion Matrix")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()


# B∆Ø·ªöC 6: TR·ª∞C QUAN H√ìA D·ªÆ LI·ªÜU B·∫∞NG t-SNE
X_flat = X_test.reshape(X_test.shape[0], -1)

# Kh·ªüi t·∫°o v√† ch·∫°y t-SNE
tsne = TSNE(n_components=2, perplexity=30, random_state=42)
X_tsne = tsne.fit_transform(X_flat)

# Nh√£n v√† m√†u s·∫Øc cho t·ª´ng lo·∫°i h√†nh ƒë·ªông
labels = ["Ng√£ v·ªÅ ph√≠a tr∆∞·ªõc", "Ng√£ v·ªÅ ph√≠a sau", "Ng√£ sang tr√°i", "Ng√£ sang ph·∫£i", "ƒê·ª©ng b√¨nh th∆∞·ªùng"]
colors = ["red", "blue", "green", "purple", "orange"]

# V·∫Ω bi·ªÉu ƒë·ªì t-SNE
plt.figure(figsize=(10, 8))
for i, label in enumerate(np.unique(y_test)):
    plt.scatter(X_tsne[y_test == label, 0], X_tsne[y_test == label, 1], 
                label=labels[i], color=colors[i], alpha=0.6)

plt.title("t-SNE Visualization of Fall Detection Data")
plt.xlabel("First t-SNE Component")
plt.ylabel("Second t-SNE Component")
plt.legend()
plt.show()

# B∆Ø·ªöC 7: T√çNH TO√ÅN PARAMETER & FLOPs
summary(model, input_size=(1, 50, 6))

#cai them thu vien
import torch.nn as nn
from torchinfo import summary

model = nn.Sequential(
    nn.Linear(6, 128),
    nn.ReLU(),
    nn.Linear(128, 50)
)

summary(model, input_size=(1, 6))

# B∆Ø·ªöC 8: XU·∫§T K·∫æT QU·∫¢ D·ª∞ ƒêO√ÅN RA FILE CSV
df = pd.DataFrame({
    "True_Label": y_test,
    "Predicted_Label": y_pred
})
df.to_csv("fall_detection_results.csv", index=False)
print("‚úÖ ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o fall_detection_results.csv")

# B∆Ø·ªöC 9: T·∫¢I FILE M√î H√åNH V·ªÄ M√ÅY
files.download("/content/fall_detection_model.h5")

# B∆Ø·ªöC 10: L∆ØU FILE K·∫æT QU·∫¢ D·ª∞ ƒêO√ÅN V·ªÄ M√ÅY
files.download("fall_detection_results.csv")
